#!/usr/bin/env python3
"""
Import dá»¯ liá»‡u vÃ o Qdrant Cloud vá»›i chiáº¿n lÆ°á»£c HYBRID
- Filter chÃ­nh xÃ¡c + Semantic search
- Metadata Ä‘áº§y Ä‘á»§ cho filtering
- Embedding text tá»‘i Æ°u (giá»¯ nguyÃªn LaTeX + context)
"""

import os
import json
import logging
import time
import re
import hashlib
from tqdm import tqdm
from dotenv import load_dotenv
from openai import OpenAI
from qdrant_client import QdrantClient
from qdrant_client.http import models
import glob

# Load environment variables from backend/.env
load_dotenv("backend/.env")

# Cáº¥u hÃ¬nh tá»« environment variables
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
QDRANT_COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "math_collection")

# Khá»Ÿi táº¡o clients
client = OpenAI(api_key=OPENAI_API_KEY)
qdrant_client = QdrantClient(
    url=QDRANT_URL,
    api_key=QDRANT_API_KEY,
)

# Cáº¥u hÃ¬nh
EMBEDDING_MODEL = "text-embedding-3-small"
VECTOR_SIZE = 1536

# Import Smart Translator
import sys
sys.path.append('data/scripts')
from smart_latex_translator import SmartLatexTranslator

# Khá»Ÿi táº¡o translator
smart_translator = SmartLatexTranslator(client)

def create_numeric_id(string_id):
    """Táº¡o numeric ID tá»« string ID Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i Qdrant Cloud"""
    # Sá»­ dá»¥ng hash Ä‘á»ƒ táº¡o ID sá»‘ nguyÃªn duy nháº¥t
    hash_object = hashlib.md5(string_id.encode())
    # Láº¥y 8 bytes Ä‘áº§u vÃ  convert thÃ nh int
    numeric_id = int.from_bytes(hash_object.digest()[:8], byteorder='big')
    # Äáº£m báº£o lÃ  sá»‘ dÆ°Æ¡ng
    return abs(numeric_id)

def translate_latex_to_natural(latex_text, context=""):
    """Dá»‹ch LaTeX thÃ nh vÄƒn báº£n tá»± nhiÃªn báº±ng Smart Translator"""
    
    if not latex_text or not latex_text.strip():
        return latex_text
    
    try:
        # Sá»­ dá»¥ng Smart Translator
        translated = smart_translator.translate(latex_text, context)
        return translated
        
    except Exception as e:
        print(f"âŒ Lá»—i dá»‹ch LaTeX: {e}")
        return latex_text

def create_enhanced_embedding_text(item):
    """Táº¡o text cho embedding - Táº­p trung vÃ o Ä‘á» bÃ i vá»›i LaTeX translation"""
    
    parts = []
    
    # === METADATA CONTEXT ===
    parts.append(f"Chá»§ Ä‘á»: {item['metadata']['category_name']}")
    parts.append(f"NÄƒm: {item['metadata']['year']}")
    parts.append(f"Loáº¡i: {item['category']} {item['subcategory']}")
    
    # === Ná»˜I DUNG Äá»€ BÃ€I (Dá»ŠCH LaTeX) - TRá»ŒNG TÃ‚M ===
    context = f"{item['metadata']['category_name']} - {item['category']}"
    problem_natural = translate_latex_to_natural(item['problem_statement'], context)
    parts.append(f"Äá» bÃ i: {problem_natural}")
    
    # ThÃªm problem parts (dá»‹ch)
    for part_key, part_content in item["problem_parts"].items():
        part_natural = translate_latex_to_natural(part_content, context)
        parts.append(f"({part_key}) {part_natural}")
    
    # === TITLE ===
    parts.append(item['title'])
    
    # === THÃŠM CONTEXT Tá»ª Lá»œI GIáº¢I (NHáº¸) ===
    # Chá»‰ thÃªm 1 dÃ²ng tÃ³m táº¯t Ä‘á»ƒ cáº£i thiá»‡n context
    if item.get('solution', {}).get('full_solution'):
        solution_preview = item['solution']['full_solution'][:100] + "..."
        solution_natural = translate_latex_to_natural(solution_preview, context)
        parts.append(f"PhÆ°Æ¡ng phÃ¡p: {solution_natural}")
    
    return "\n".join(parts)

def get_embedding(text):
    """Táº¡o semantic embedding tá»« OpenAI"""
    try:
        response = client.embeddings.create(
            model=EMBEDDING_MODEL,
            input=text
        )
        return response.data[0].embedding
    except Exception as e:
        print(f"âŒ Lá»—i táº¡o embedding: {e}")
        return None

def create_keyword_vector(text):
    """Táº¡o keyword vector (sparse) cho hybrid search - Simple TF-IDF approach"""
    
    # Simple keyword extraction cho Vietnamese math terms
    import re
    from collections import Counter
    
    # Normalize text
    text_lower = text.lower()
    
    # Extract important math keywords
    math_keywords = [
        'ma tráº­n', 'matrix', 'Ä‘á»‹nh thá»©c', 'det', 'háº¡ng', 'rank',
        'phÆ°Æ¡ng trÃ¬nh', 'equation', 'há»‡', 'system', 'nghiá»‡m', 'solution',
        'giÃ¡ trá»‹ riÃªng', 'eigenvalue', 'vector riÃªng', 'eigenvector',
        'khÃ´ng gian', 'space', 'tuyáº¿n tÃ­nh', 'linear', 'Ä‘á»™c láº­p', 'independent',
        'tÃ­ch phÃ¢n', 'integral', 'Ä‘áº¡o hÃ m', 'derivative', 'giá»›i háº¡n', 'limit',
        'tá»• há»£p', 'combination', 'Ä‘a thá»©c', 'polynomial'
    ]
    
    # Simple keyword scoring
    keyword_scores = {}
    for i, keyword in enumerate(math_keywords):
        count = text_lower.count(keyword)
        if count > 0:
            keyword_scores[i] = float(count)
    
    # Convert to sparse vector format (simple approach)
    # Note: Trong production, nÃªn dÃ¹ng SPLADE hoáº·c BM25
    return keyword_scores if keyword_scores else None

def create_collection():
    """Táº¡o collection vá»›i MULTI-VECTOR schema theo khuyáº¿n nghá»‹ Gemini"""
    
    collection_name = QDRANT_COLLECTION_NAME  # Sá»­ dá»¥ng tÃªn tá»« .env
    
    try:
        # Kiá»ƒm tra collection cÅ© (KHÃ”NG xÃ³a tá»± Ä‘á»™ng Ä‘á»ƒ trÃ¡nh máº¥t dá»¯ liá»‡u)
        try:
            existing = qdrant_client.get_collection(collection_name)
            print(f"âš ï¸ Collection {collection_name} Ä‘Ã£ tá»“n táº¡i. Sáº½ thÃªm dá»¯ liá»‡u vÃ o collection hiá»‡n cÃ³.")
        except:
            print(f"ğŸ“ Táº¡o collection má»›i: {collection_name}")
        
        # Táº¡o collection vá»›i MULTI-VECTOR configuration (chá»‰ khi chÆ°a tá»“n táº¡i)
        try:
            qdrant_client.get_collection(collection_name)
            print(f"âœ… Collection {collection_name} Ä‘Ã£ tá»“n táº¡i, bá» qua táº¡o má»›i")
        except:
            qdrant_client.create_collection(
                collection_name=collection_name,
                vectors_config={
                    # Vector dÃ y cho semantic search
                    "semantic_vector": models.VectorParams(
                        size=VECTOR_SIZE,  # 1536 for text-embedding-3-small
                        distance=models.Distance.COSINE
                    ),
                    # Vector thÆ°a cho keyword matching (sáº½ implement sau)
                    # "keyword_vector": models.SparseVectorParams()
                }
            )
            print(f"âœ… ÄÃ£ táº¡o collection má»›i: {collection_name}")
        
        # Táº¡o RICH PAYLOAD INDEXES theo Gemini Table 2.1.1 + problem_section
        payload_indexes = [
            # Core identifiers
            ("doc_id", models.PayloadSchemaType.KEYWORD),
            ("source_file", models.PayloadSchemaType.KEYWORD),
            
            # Filtering fields
            ("category", models.PayloadSchemaType.KEYWORD),
            ("subcategory", models.PayloadSchemaType.KEYWORD),
            ("metadata.year", models.PayloadSchemaType.INTEGER),
            ("metadata.difficulty", models.PayloadSchemaType.KEYWORD),
            ("metadata.subject", models.PayloadSchemaType.KEYWORD),
            
            # Question filtering (NEW)
            ("question_number", models.PayloadSchemaType.KEYWORD),
            ("problem_section", models.PayloadSchemaType.KEYWORD),
            
            # Full-text search fields
            ("latex_string", models.PayloadSchemaType.TEXT),
            ("natural_language_desc", models.PayloadSchemaType.TEXT),
        ]
        
        for field_name, field_type in payload_indexes:
            try:
                qdrant_client.create_payload_index(
                    collection_name=collection_name,
                    field_name=field_name,
                    field_schema=field_type
                )
                print(f"   âœ… Created index: {field_name} ({field_type})")
            except Exception as e:
                print(f"   âš ï¸ Index {field_name}: {e}")
        
        print(f"âœ… ÄÃ£ táº¡o collection: {collection_name}")
        print("âœ… ÄÃ£ táº¡o indexes cho filtering")
        
    except Exception as e:
        print(f"âŒ Lá»—i táº¡o collection {collection_name}: {e}")
        return False
    
    return True

def extract_problem_section(question_number: str, category: str) -> str:
    """Extract problem section from question_number based on category."""
    if not question_number:
        return ""
    
    if category == "dethi":
        # For dethi: section = question_number (e.g., "1" -> "1")
        return question_number.strip()
    elif category == "baitap":
        # For baitap: section = part before dot (e.g., "1.2" -> "1")
        if "." in question_number:
            return question_number.split(".")[0].strip()
        else:
            return question_number.strip()
    else:
        return question_number.strip()


def upload_item_to_qdrant(item):
    """Upload item vá»›i MULTI-VECTOR schema vÃ  RICH PAYLOAD + problem_section"""
    
    try:
        # === Táº O SEMANTIC VECTOR ===
        embedding_text = create_enhanced_embedding_text(item)
        semantic_vector = get_embedding(embedding_text)
        
        if semantic_vector is None:
            return False
        
        # === Dá»ŠCH TOÃ€N Bá»˜ Ná»˜I DUNG ===
        context = f"{item['metadata']['category_name']} - {item['category']}"
        
        # Dá»‹ch Ä‘á» bÃ i
        problem_natural = translate_latex_to_natural(item['problem_statement'], context)
        
        # Dá»‹ch problem parts
        problem_parts_natural = {}
        for part_key, part_content in item["problem_parts"].items():
            problem_parts_natural[part_key] = translate_latex_to_natural(part_content, context)
        
        # Dá»‹ch lá»i giáº£i
        solution_natural = {}
        if item.get('solution', {}).get('full_solution'):
            solution_natural['full_solution'] = translate_latex_to_natural(
                item['solution']['full_solution'], context
            )
        
        # Dá»‹ch solution parts
        solution_parts_natural = {}
        for part_key, part_content in item.get('solution', {}).get('solution_parts', {}).items():
            solution_parts_natural[part_key] = translate_latex_to_natural(part_content, context)
        
        if solution_parts_natural:
            solution_natural['solution_parts'] = solution_parts_natural
        
        # === THÃŠM PROBLEM_SECTION ===
        question_number = item.get("question_number", "")
        category = item.get("category", "")
        problem_section = extract_problem_section(question_number, category)
        
        # === Táº O RICH PAYLOAD theo Gemini Table 2.1.1 + problem_section ===
        payload = {
            # Core identifiers (theo Gemini schema)
            "doc_id": item["id"],
            "source_file": item["metadata"]["source_file"],
            
            # Filtering fields
            "category": item["category"],
            "subcategory": item["subcategory"],
            "metadata": item["metadata"],  # Giá»¯ nguyÃªn Ä‘á»ƒ backward compatibility
            
            # LaTeX content (cho full-text search)
            "latex_string": item["problem_statement"],
            "natural_language_desc": problem_natural,
            
            # Complete content (giá»¯ nguyÃªn structure cÅ©)
            "title": item["title"],
            "question_number": item["question_number"],
            "source_path": item["source_path"],
            "problem_statement": item["problem_statement"],
            "problem_parts": item["problem_parts"],
            "solution": item["solution"],
            
            # Enhanced natural language content
            "problem_statement_natural": problem_natural,
            "problem_parts_natural": problem_parts_natural,
            "solution_natural": solution_natural,
            
            # NEW: Problem section for advanced filtering
            "problem_section": problem_section,
            
            # Search optimization
            "content_type": "hybrid_v3",  # Updated version
            "embedding_text": embedding_text  # Äá»ƒ debug vÃ  analysis
        }
        
        # === Táº O NUMERIC ID cho Qdrant Cloud ===
        numeric_id = create_numeric_id(item["id"])
        
        # === UPLOAD VÃ€O QDRANT vá»›i MULTI-VECTOR ===
        qdrant_client.upsert(
            collection_name=QDRANT_COLLECTION_NAME,  # Sá»­ dá»¥ng collection name tá»« .env
            points=[{
                "id": numeric_id,  # Sá»­ dá»¥ng numeric ID
                "vector": {
                    "semantic_vector": semantic_vector
                    # "keyword_vector": keyword_vector  # Sáº½ implement sau
                },
                "payload": payload
            }]
        )
        
        return True
        
    except Exception as e:
        print(f"âŒ Lá»—i upload item {item['id']}: {e}")
        return False

def load_and_upload_data():
    """Load vÃ  upload táº¥t cáº£ dá»¯ liá»‡u JSON"""
    
    # TÃ¬m táº¥t cáº£ file JSON
    json_pattern = "data/processed/final/**/*.json"
    json_files = glob.glob(json_pattern, recursive=True)
    
    # Loáº¡i bá» file summary
    json_files = [f for f in json_files if "processing_summary.json" not in f]
    
    print(f"ğŸ“ TÃ¬m tháº¥y {len(json_files)} file JSON")
    
    total_items = 0
    success_count = 0
    
    for json_file in tqdm(json_files, desc="Xá»­ lÃ½ files"):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            print(f"\nğŸ“„ Xá»­ lÃ½ file: {json_file}")
            print(f"   ğŸ“Š Sá»‘ items: {len(data)}")
            
            for item in tqdm(data, desc="Upload items", leave=False):
                total_items += 1
                if upload_item_to_qdrant(item):
                    success_count += 1
                else:
                    print(f"âŒ Lá»—i upload: {item['id']}")
                
                # Delay nhá» Ä‘á»ƒ trÃ¡nh rate limit
                time.sleep(0.1)
                
        except Exception as e:
            print(f"âŒ Lá»—i xá»­ lÃ½ file {json_file}: {e}")
    
    print(f"\nğŸ‰ HOÃ€N THÃ€NH!")
    print(f"ğŸ“Š Tá»•ng items: {total_items}")
    print(f"âœ… Upload thÃ nh cÃ´ng: {success_count}")
    print(f"âŒ Lá»—i: {total_items - success_count}")
    
    return success_count

def test_search_functionality():
    """Test chá»©c nÄƒng tÃ¬m kiáº¿m vá»›i filter"""
    
    print("\nğŸ§ª TEST SEARCH FUNCTIONALITY")
    
    test_queries = [
        {
            "query": "Ä‘á» thi báº£ng A nÄƒm 2024",
            "expected_filters": {
                "category": "dethi",
                "subcategory": "bangA", 
                "year": 2024
            }
        },
        {
            "query": "bÃ i táº­p ma tráº­n nÄƒm 2018",
            "expected_filters": {
                "category": "baitap",
                "subcategory": "mt",
                "year": 2018
            }
        }
    ]
    
    for test in test_queries:
        print(f"\nğŸ” Query: {test['query']}")
        
        # Táº¡o filter conditions
        must_conditions = []
        for key, value in test['expected_filters'].items():
            if key == "year":
                must_conditions.append({
                    "key": "metadata.year",
                    "match": {"value": value}
                })
            else:
                must_conditions.append({
                    "key": key,
                    "match": {"value": value}
                })
        
        query_filter = {"must": must_conditions} if must_conditions else None
        
        try:
            # TÃ¬m kiáº¿m vá»›i filter trÃªn MULTI-VECTOR collection
            query_vector = get_embedding(test['query'])
            results = qdrant_client.search(
                collection_name=QDRANT_COLLECTION_NAME,
                query_vector=("semantic_vector", query_vector),  # Chá»‰ Ä‘á»‹nh vector name
                query_filter=query_filter,
                limit=5,
                with_vectors=False  # KhÃ´ng cáº§n tráº£ vá» vectors Ä‘á»ƒ tiáº¿t kiá»‡m bandwidth
            )
            
            print(f"   ğŸ“Š Káº¿t quáº£: {len(results)} items")
            for i, result in enumerate(results[:3]):
                payload = result.payload
                print(f"   {i+1}. {payload['title']} (Score: {result.score:.3f})")
                print(f"      Category: {payload['category']}/{payload['subcategory']}")
                print(f"      Year: {payload['metadata']['year']}")
                
        except Exception as e:
            print(f"   âŒ Lá»—i search: {e}")

def load_and_upload_data():
    """Load vÃ  upload táº¥t cáº£ dá»¯ liá»‡u JSON"""
    
    # TÃ¬m táº¥t cáº£ file JSON
    json_files = glob.glob("data/processed/final/**/*.json", recursive=True)
    json_files = [f for f in json_files if "processing_summary.json" not in f]
    
    print(f"ğŸ“ TÃ¬m tháº¥y {len(json_files)} files")
    
    total_success = 0
    total_items = 0
    
    for json_file in json_files:
        print(f"\nğŸ“„ Xá»­ lÃ½: {json_file}")
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                items = json.load(f)
            
            print(f"   ğŸ“Š {len(items)} items")
            total_items += len(items)
            
            # Upload tá»«ng item
            for item in items:
                if upload_item_to_qdrant(item):
                    total_success += 1
                    print(f"   âœ… {total_success}/{total_items} uploaded", end='\r')
                else:
                    print(f"   âŒ Lá»—i upload item {item.get('id', 'unknown')}")
                
                # Rate limiting Ä‘á»ƒ trÃ¡nh quÃ¡ táº£i
                time.sleep(0.1)
                
        except Exception as e:
            print(f"âŒ Lá»—i xá»­ lÃ½ file {json_file}: {e}")
    
    print(f"\nğŸ“Š Tá»•ng káº¿t: {total_success}/{total_items} items uploaded thÃ nh cÃ´ng")
    return total_success

def main():
    """HÃ m main"""
    
    print("ğŸš€ Báº®T Äáº¦U IMPORT Dá»® LIá»†U VÃ€O QDRANT CLOUD")
    print("=" * 50)
    
    # Kiá»ƒm tra cáº¥u hÃ¬nh
    if not all([OPENAI_API_KEY, QDRANT_URL, QDRANT_API_KEY]):
        print("âŒ Thiáº¿u cáº¥u hÃ¬nh environment variables!")
        return
    
    print(f"ğŸ”— QDRANT_URL: {QDRANT_URL}")
    print(f"ğŸ“¦ COLLECTION: {QDRANT_COLLECTION_NAME}")
    
    # Táº¡o collection
    if not create_collection():
        return
    
    # Upload dá»¯ liá»‡u
    success_count = load_and_upload_data()
    
    if success_count > 0:
        # Test search
        test_search_functionality()
        
        print(f"\nğŸ‰ THÃ€NH CÃ”NG! ÄÃ£ upload {success_count} items vÃ o Qdrant Cloud")
    else:
        print("\nâŒ THáº¤T Báº I! KhÃ´ng upload Ä‘Æ°á»£c item nÃ o")

if __name__ == "__main__":
    main()
