# üöÄ H∆Ø·ªöNG D·∫™N C·∫§U TR√öC M·ªöI - AI MATH CHATBOT

## üìã T·ªïng quan

H·ªá th·ªëng AI Math Chatbot ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t v·ªõi c·∫•u tr√∫c d·ªØ li·ªáu m·ªõi v√† RAG system ti√™n ti·∫øn, h·ªó tr·ª£ c√°c field:
- `category`: dethi, baitap
- `subcategory`: bangA, bangB, gtr, hpt, dstuyentinh
- `subject_area`: dai_so_tuyen_tinh, giai_tich, hinh_hoc, xac_suat_thong_ke
- `difficulty_level`: co_ban, trung_binh, kho, quoc_gia
- `problem_type`: dethi, baitap, thuchanh

## üîÑ C√°c thay ƒë·ªïi ch√≠nh

### 1. MetadataExtractor (‚úÖ ƒê√£ c·∫≠p nh·∫≠t)

**File:** `backend/app/services/llm/metadata_extractor.py`

**Thay ƒë·ªïi:**
- Th√™m c√°c field m·ªõi v√†o `MathQueryMetadata`
- C·∫≠p nh·∫≠t prompt ƒë·ªÉ extract c·∫•u tr√∫c m·ªõi
- Gi·ªØ backward compatibility v·ªõi c·∫•u tr√∫c c≈©
- T√≠ch h·ª£p v·ªõi RAG system

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from app.services.llm.metadata_extractor import MetadataExtractor

extractor = MetadataExtractor()
metadata = await extractor.extract_metadata("Cho t√¥i b√†i 1 ƒë·ªÅ thi b·∫£ng A v·ªÅ ma tr·∫≠n")

# C·∫•u tr√∫c m·ªõi
print(metadata.category)        # "dethi"
print(metadata.subcategory)    # "bangA"
print(metadata.subject_area)   # "dai_so_tuyen_tinh"

# C·∫•u tr√∫c c≈© (v·∫´n ho·∫°t ƒë·ªông)
print(metadata.level)          # "a"
print(metadata.year)           # 2024 (n·∫øu c√≥)
```

### 2. RAG System (‚úÖ ƒê√£ ho√†n thi·ªán)

**Files:**
- `backend/app/rag/rag_service.py` - Core RAG logic
- `backend/app/rag/qdrant_connector.py` - Vector database connection
- `backend/app/rag/retriever_semantic.py` - Semantic search
- `backend/app/rag/context_builder.py` - Context building

**T√≠nh nƒÉng:**
- Retrieval-Augmented Generation v·ªõi Qdrant
- Semantic search th√¥ng minh
- Metadata filtering n√¢ng cao
- Context building t·ª± ƒë·ªông
- Integration v·ªõi Gemini LLM

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from app.rag.rag_service import RAGService

rag_service = RAGService()

# T√¨m ki·∫øm v·ªõi RAG
context, success = await rag_service.get_context(
    query="gi·∫£i ph∆∞∆°ng tr√¨nh b·∫≠c 2",
    problem_only=True
)

# Generate response v·ªõi context
response = await rag_service.generate_response(
    query="gi·∫£i ph∆∞∆°ng tr√¨nh b·∫≠c 2",
    context=context
)
```

### 3. Data Pipeline (‚úÖ ƒê√£ ho√†n thi·ªán)

**Files:**
- `data/scripts/final_md_to_json_processor.py` - Markdown ‚Üí JSON
- `data/scripts/import_to_qdrant_hybrid.py` - Upload to Qdrant
- `data/scripts/smart_latex_translator.py` - LaTeX translation

**Workflow:**
```
Markdown Files ‚Üí JSON Processing ‚Üí Vector Embeddings ‚Üí Qdrant Storage
```

### 4. MathProblemTemplates (‚úÖ M·ªõi t·∫°o)

**File:** `backend/app/services/llm/prompt_templates.py`

**Ch·ª©c nƒÉng:**
- Format context t·ª´ documents v·ªõi c·∫•u tr√∫c m·ªõi
- H·ªó tr·ª£ c·∫£ problem_statement v√† page_content
- Hi·ªÉn th·ªã metadata phong ph√∫ (difficulty, subject_area, etc.)
- Template cho search summary v√† no results message
- Integration v·ªõi RAG system

**V√≠ d·ª• s·ª≠ d·ª•ng:**
```python
from app.services.llm.prompt_templates import MathProblemTemplates

# Format context
formatted = MathProblemTemplates.format_problem_context(documents, problem_only=False)

# Format search summary
summary = MathProblemTemplates.format_search_summary(query, documents, metadata)
```

### 5. QdrantConnector (‚úÖ ƒê√£ ho√†n thi·ªán)

**File:** `backend/app/rag/qdrant_connector.py`

**Tr·∫°ng th√°i:** 
- H·ªó tr·ª£ filter t·ªïng qu√°t v·ªõi c√°c field m·ªõi
- Vector search v·ªõi embeddings
- Metadata filtering n√¢ng cao
- Batch operations cho data upload

## üîó Mapping c·∫•u tr√∫c c≈© sang m·ªõi

| C·∫•u tr√∫c c≈© | C·∫•u tr√∫c m·ªõi |
|-------------|--------------|
| `level: "a"` | `category: "dethi", subcategory: "bangA"` |
| `level: "b"` | `category: "dethi", subcategory: "bangB"` |
| `topic: "ƒë·ªÅ thi b·∫£ng A"` | `category: "dethi", subcategory: "bangA"` |
| `tags: ["ma tr·∫≠n"]` | `subject_area: "dai_so_tuyen_tinh"` |

## üöÄ C√°ch s·ª≠ d·ª•ng h·ªá th·ªëng m·ªõi

### 1. Kh·ªüi t·∫°o RAG Service
```python
from app.rag.rag_service import RAGService
from app.services.llm.metadata_extractor import MetadataExtractor

# Kh·ªüi t·∫°o services
rag_service = RAGService()
metadata_extractor = MetadataExtractor()
```

### 2. X·ª≠ l√Ω query v·ªõi metadata
```python
# Extract metadata
metadata = await metadata_extractor.extract_metadata(
    "Cho t√¥i b√†i t·∫≠p v·ªÅ ma tr·∫≠n kh√≥"
)

# S·ª≠ d·ª•ng RAG ƒë·ªÉ t√¨m ki·∫øm
context, success = await rag_service.get_context(
    query="Cho t√¥i b√†i t·∫≠p v·ªÅ ma tr·∫≠n kh√≥",
    metadata=metadata,
    problem_only=True
)
```

### 3. Generate response
```python
# Generate response v·ªõi context
response = await rag_service.generate_response(
    query="Cho t√¥i b√†i t·∫≠p v·ªÅ ma tr·∫≠n kh√≥",
    context=context,
    metadata=metadata
)
```

## üìä C·∫•u tr√∫c d·ªØ li·ªáu m·ªõi

### Document Schema
```json
{
  "id": "unique_id",
  "content": "N·ªôi dung b√†i t·∫≠p/l·ªùi gi·∫£i",
  "metadata": {
    "category": "dethi|baitap",
    "subcategory": "bangA|bangB|gtr|hpt|dstuyentinh",
    "subject_area": "dai_so_tuyen_tinh|giai_tich|hinh_hoc|xac_suat_thong_ke",
    "difficulty_level": "co_ban|trung_binh|kho|quoc_gia",
    "problem_type": "dethi|baitap|thuchanh",
    "year": 2024,
    "source": "Olympic B√°ch Khoa"
  },
  "vector": [0.1, 0.2, ...],
  "created_at": "2024-01-01T00:00:00Z"
}
```

### Filter Examples
```python
# Filter theo category v√† difficulty
filters = {
    "category": "baitap",
    "difficulty_level": "kho"
}

# Filter theo subject area
filters = {
    "subject_area": "dai_so_tuyen_tinh"
}

# Filter k·∫øt h·ª£p
filters = {
    "category": "dethi",
    "subcategory": "bangA",
    "subject_area": "giai_tich"
}
```

## üîß C·∫•u h√¨nh h·ªá th·ªëng

### Environment Variables
```env
# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION=math_problems

# Gemini API
GOOGLE_API_KEY=your_api_key_here

# Database
DATABASE_URL=sqlite:///./aichatbot.db
```

### Docker Compose
```yaml
version: '3.8'
services:
  qdrant:
    image: qdrant/qdrant
    ports:
      - "6333:6333"
    volumes:
      - qdrant_storage:/qdrant/storage

  backend:
    build: ./backend
    ports:
      - "8000:8000"
    depends_on:
      - qdrant
```

## üìà Performance & Monitoring

### Metrics
- Query response time
- Context retrieval accuracy
- Vector search performance
- Memory usage

### Logging
```python
import logging

logger = logging.getLogger(__name__)
logger.info(f"RAG query processed: {query}")
logger.info(f"Context retrieved: {len(context)} documents")
```

## üéØ Roadmap t∆∞∆°ng lai

### Giai ƒëo·∫°n ng·∫Øn h·∫°n
- [ ] Performance optimization
- [ ] Advanced filtering
- [ ] Caching layer

### Giai ƒëo·∫°n trung h·∫°n
- [ ] Multi-language support
- [ ] Advanced analytics
- [ ] A/B testing framework

### Giai ƒëo·∫°n d√†i h·∫°n
- [ ] Cloud deployment
- [ ] Auto-scaling
- [ ] Advanced ML models

---

**H·ªá th·ªëng AI Math Chatbot v·ªõi RAG system ƒë√£ s·∫µn s√†ng cho production! üöÄ‚ú®**