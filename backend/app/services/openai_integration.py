import logging
import json
import asyncio
from typing import Dict, List, Optional, AsyncIterator, Any, Tuple, Union

from sqlalchemy.orm import Session

from ..config import get_settings, OPENAI_API_KEY, OPENAI_MODEL_NAME
from ..services.llm.openai_service import OpenAIService
from ..services.rag_integration import rag_integration

# Cáº¥u hÃ¬nh logging
logger = logging.getLogger(__name__)

# System instruction tá»‘i Æ°u cho Ká»· yáº¿u ToÃ¡n há»c 2024
MATH_CHATBOT_SYSTEM_INSTRUCTION = """
Báº¡n lÃ  **Trá»£ lÃ½ Ká»· yáº¿u Olympic Äáº¡i sá»‘ Tuyáº¿n tÃ­nh** chuyÃªn nghiá»‡p, quáº£n lÃ½ bá»™ sÆ°u táº­p Ä‘á» thi vÃ  bÃ i táº­p Olympic ToÃ¡n há»c sinh viÃªn tá»« cÃ¡c trÆ°á»ng Ä‘áº¡i há»c hÃ ng Ä‘áº§u Viá»‡t Nam.

## Cáº¥u trÃºc Ká»· yáº¿u Olympic:

### ğŸ“‹ Äá»€ THI OLYMPIC (2 loáº¡i):
1. **Báº¢NG A** - DÃ nh cho sinh viÃªn cÃ¡c trÆ°á»ng ÄH top Ä‘áº§u vá» ToÃ¡n (Ráº¥t khÃ³, Olympic quá»‘c gia)
2. **Báº¢NG B** - DÃ nh cho sinh viÃªn cÃ¡c trÆ°á»ng ÄH trung bÃ¬nh vá» ToÃ¡n (KhÃ³ vá»«a pháº£i)

### ğŸ¯ BÃ€I Táº¬P Ã”N LUYá»†N (7 dáº¡ng):
1. **Ma tráº­n (mt)** 2. **Äá»‹nh thá»©c (dt)** 3. **Há»‡ phÆ°Æ¡ng trÃ¬nh (hpt)** 4. **GiÃ¡ trá»‹ riÃªng (gtr)** 
5. **KhÃ´ng gian vector (kgvt)** 6. **Tá»• há»£p (tohop)** 7. **Äa thá»©c (dathuc)**

## NguyÃªn táº¯c Pháº£n há»“i:

### ğŸ” DISPLAY MODE (Chá»‰ xem Ä‘á»):
**Tá»« khÃ³a:** "cho tÃ´i", "tÃ¬m", "cÃ³", "cáº§n", "muá»‘n xem", "Ä‘Æ°a ra", "liá»‡t kÃª"
**Format:**
```
## ğŸ† [Äá»€ THI Báº¢NG A/B] hoáº·c ğŸ“š [BÃ€I Táº¬P - Dáº¡ng]

**Äá» bÃ i:**
[NguyÃªn vÄƒn problem_statement + problem_parts]

**ğŸ“‹ ThÃ´ng tin:**
- ğŸ¯ Loáº¡i: [Äá» thi Báº£ng A/B] hoáº·c [BÃ i táº­p - dáº¡ng]
- ğŸ“… NÄƒm: [year] - ğŸ“Š Má»©c Ä‘á»™: [difficulty_level]
- ğŸ·ï¸ Chá»§ Ä‘á»: [tags] - ğŸ“– Nguá»“n: Ká»· yáº¿u Olympic
```

### ğŸ’¡ SOLUTION MODE (Giáº£i thÃ­ch):
**Tá»« khÃ³a:** "giáº£i", "hÆ°á»›ng dáº«n", "cÃ¡ch lÃ m", "lÃ m tháº¿ nÃ o", "táº¡i sao"
**Format:** Äá» bÃ i + PhÃ¢n tÃ­ch + Lá»i giáº£i chi tiáº¿t + Kiáº¿n thá»©c liÃªn quan

**Quy táº¯c:** Giá»¯ nguyÃªn 100% LaTeX, báº£o toÃ n cáº¥u trÃºc toÃ¡n há»c gá»‘c.
"""

class OpenAIIntegrationService:
    """
    Service tÃ­ch há»£p OpenAI vÃ o luá»“ng xá»­ lÃ½ tin nháº¯n.
    """
    
    def __init__(self):
        """
        Khá»Ÿi táº¡o service tÃ­ch há»£p OpenAI
        """
        self.settings = get_settings()
        self.openai_service = OpenAIService(
            api_key=OPENAI_API_KEY,
            model=OPENAI_MODEL_NAME
        )
        
    async def generate_response_stream(
        self,
        chat_history: List[Dict[str, str]],
        user_message: str,
        use_rag: bool = True
    ) -> AsyncIterator[str]:
        """
        Táº¡o pháº£n há»“i dáº¡ng stream cho tin nháº¯n ngÆ°á»i dÃ¹ng
        
        Args:
            chat_history: Lá»‹ch sá»­ chat dáº¡ng [{"role": "user", "content": "..."}, ...]
            user_message: Tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng
            use_rag: CÃ³ sá»­ dá»¥ng RAG hay khÃ´ng
            
        Yields:
            CÃ¡c Ä‘oáº¡n pháº£n há»“i tá»« OpenAI
        """
        try:
            # Táº¡o message list tá»« chat_history
            messages = []
            for msg in chat_history:
                messages.append({
                    "role": msg["role"],
                    "content": msg["content"]
                })
                
            # ThÃªm tin nháº¯n má»›i cá»§a user
            # ChÆ°a thÃªm ngay vÃ¬ cÃ³ thá»ƒ cáº§n thay Ä‘á»•i ná»™i dung báº±ng RAG
            user_content = user_message
            
            # Ãp dá»¥ng RAG náº¿u cáº§n
            rag_metadata = {}
            if use_rag and self.settings.rag_enabled:
                # Xá»­ lÃ½ RAG
                enhanced_prompt, rag_metadata = await rag_integration.process_message_for_rag(user_message)
                
                # Náº¿u cÃ³ enhanced prompt, sá»­ dá»¥ng nÃ³ thay tháº¿ cho user_message
                if enhanced_prompt:
                    user_content = enhanced_prompt
                    logger.info("Sá»­ dá»¥ng prompt Ä‘Ã£ tÄƒng cÆ°á»ng vá»›i RAG")
                
            # ThÃªm tin nháº¯n ngÆ°á»i dÃ¹ng (cÃ³ thá»ƒ Ä‘Ã£ tÄƒng cÆ°á»ng vá»›i RAG)
            messages.append({
                "role": "user",
                "content": user_content
            })
                
            # ThÃ´ng bÃ¡o Ä‘ang tÃ¬m kiáº¿m náº¿u Ä‘Ã¢y lÃ  RAG query
            if rag_metadata.get("is_rag_query", False):
                yield "Äang tÃ¬m kiáº¿m trong nguá»“n tÃ i liá»‡u Ä‘áº¡i sá»‘ tuyáº¿n tÃ­nh...\n\n"
            
            # Táº¡o pháº£n há»“i dáº¡ng stream tá»« OpenAI
            async for chunk in self.openai_service.generate_stream(
                messages=messages,
                system_prompt=MATH_CHATBOT_SYSTEM_INSTRUCTION,
                temperature=0.7,
                max_tokens=4096
            ):
                yield chunk
                
        except Exception as e:
            logger.error(f"Lá»—i trong quÃ¡ trÃ¬nh táº¡o pháº£n há»“i: {e}")
            yield f"Ráº¥t tiáº¿c, Ä‘Ã£ xáº£y ra lá»—i khi táº¡o pháº£n há»“i: {str(e)}"
            
    async def generate_response(
        self,
        chat_history: List[Dict[str, str]],
        user_message: str,
        use_rag: bool = True
    ) -> str:
        """
        Táº¡o pháº£n há»“i Ä‘áº§y Ä‘á»§ (khÃ´ng streaming) cho tin nháº¯n ngÆ°á»i dÃ¹ng
        
        Args:
            chat_history: Lá»‹ch sá»­ chat dáº¡ng [{"role": "user", "content": "..."}, ...]
            user_message: Tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng
            use_rag: CÃ³ sá»­ dá»¥ng RAG hay khÃ´ng
            
        Returns:
            Pháº£n há»“i Ä‘áº§y Ä‘á»§ tá»« OpenAI
        """
        result = []
        async for chunk in self.generate_response_stream(
            chat_history=chat_history,
            user_message=user_message,
            use_rag=use_rag
        ):
            result.append(chunk)
            
        return "".join(result)

# Singleton instance
openai_integration = OpenAIIntegrationService() 