import sys
import os
import logging
import importlib.util
from typing import List, Optional, Dict, Any, Tuple
try:
    from langchain_core.documents import Document
except ImportError:
    # Fallback for development environment
    class Document:
        def __init__(self, page_content: str = "", metadata: dict = None):
            self.page_content = page_content
            self.metadata = metadata or {}

# Import tr·ª±c ti·∫øp t·ª´ config/__init__.py
from ..config import get_settings

# ƒê∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi ƒë·∫øn c√°c module
app_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
rag_path = os.path.abspath(os.path.dirname(__file__))

# Import app/rag/config/config.py
rag_config_path = os.path.join(rag_path, "config", "config.py")
spec = importlib.util.spec_from_file_location("rag_config", rag_config_path)
rag_config = importlib.util.module_from_spec(spec)
spec.loader.exec_module(rag_config)

# L·∫•y c√°c bi·∫øn config c·∫ßn thi·∫øt
rag_settings = rag_config.rag_settings

# Import c√°c module kh√°c
from .qdrant_connector import QdrantConnector
# from .query_extractor import QueryMetadataExtractor  # Deprecated - using VN parser
from .query_extractor_vn import parse_query, build_qdrant_filter
from ..services.llm.metadata_extractor import MetadataExtractor, MathQueryMetadata
from .context_builder import assemble_context

logger = logging.getLogger(__name__)

class RAGService:
    """
    Service cho Retrieval Augmented Generation (RAG)
    """
    
    def __init__(self, qdrant_connector: Optional[QdrantConnector] = None, metadata_extractor: Optional[MetadataExtractor] = None):
        """
        Kh·ªüi t·∫°o RAG Service
        
        Args:
            qdrant_connector: QdrantConnector instance (t·∫°o m·ªõi n·∫øu kh√¥ng c√≥)
            metadata_extractor: MetadataExtractor instance (t·∫°o m·ªõi n·∫øu kh√¥ng c√≥)
        """
        self.settings = get_settings()
        self.rag_settings = rag_settings
        try:
            self.qdrant = qdrant_connector or QdrantConnector()
        except Exception as e:
            logger.error(f"Failed to initialize QdrantConnector: {str(e)}")
            self.qdrant = None
            logger.warning("RAG Service initialized without Qdrant connection. Fallback will be used.")
        
        # Kh·ªüi t·∫°o metadata extractor m·ªõi
        try:
            self.metadata_extractor = metadata_extractor or MetadataExtractor()
        except Exception as e:
            logger.error(f"Failed to initialize MetadataExtractor: {str(e)}")
            self.metadata_extractor = None
            logger.warning("RAG Service initialized without MetadataExtractor. Will use old method.")
        
    def _extract_metadata_from_query(self, query: str) -> Dict:
        """
        Tr√≠ch xu·∫•t metadata t·ª´ c√¢u truy v·∫•n ƒë·ªÉ c·∫£i thi·ªán t√¨m ki·∫øm
        
        Args:
            query: C√¢u truy v·∫•n ng∆∞·ªùi d√πng
            
        Returns:
            Dict: C√°c b·ªô l·ªçc ph√π h·ª£p v·ªõi truy v·∫•n
        """
        try:
            # Use VN parser instead of old QueryMetadataExtractor
            vn_parsed = parse_query(query)
            extracted_metadata = {
                "category": vn_parsed.category,
                "subcategory": vn_parsed.subcategory,
                "year": vn_parsed.year,
                "question_code": vn_parsed.question_code,
                "question_num": vn_parsed.question_num
            }
            if any(extracted_metadata.values()):
                logger.info(f"VN parsed metadata from query: {extracted_metadata}")
            return extracted_metadata
        except Exception as e:
            logger.warning(f"Error extracting metadata from query: {str(e)}")
            return {}
    
    def _log_document_details(self, documents: List[Document], prefix: str = ""):
        """
        Log chi ti·∫øt v·ªÅ c√°c documents t√¨m ƒë∆∞·ª£c ƒë·ªÉ debug
        
        Args:
            documents: Danh s√°ch documents c·∫ßn log
            prefix: Ti·ªÅn t·ªë th√¥ng tin log
        """
        logger.info(f"{prefix} Found {len(documents)} documents")
        
        for i, doc in enumerate(documents[:3]):  # Log t·ªëi ƒëa 3 documents
            logger.info(f"{prefix} Document {i+1}:")
            
            # Log metadata
            if hasattr(doc, "metadata") and isinstance(doc.metadata, dict):
                metadata_str = ", ".join([f"{k}={v}" for k, v in doc.metadata.items() 
                                         if k in ["question", "year", "tags", "type", "source", "title"]])
                logger.info(f"{prefix} - Metadata: {metadata_str}")
            
            # Log content summary
            if hasattr(doc, "page_content"):
                content_preview = doc.page_content[:100].replace("\n", " ")
                logger.info(f"{prefix} - Content preview: {content_preview}...")
    
    async def get_context(
        self, 
        query: str, 
        filter: Optional[Dict] = None,
        k: Optional[int] = None,
        use_query_metadata: bool = True,
        problem_only: bool = False
    ) -> Tuple[List[Document], bool]:
        """
        L·∫•y ng·ªØ c·∫£nh cho truy v·∫•n t·ª´ vector database
        Bao g·ªìm c∆° ch·∫ø fallback
        
        Args:
            query: Truy v·∫•n ng∆∞·ªùi d√πng
            filter: B·ªô l·ªçc metadata
            k: S·ªë l∆∞·ª£ng documents l·∫•y v·ªÅ
            use_query_metadata: C√≥ tr√≠ch xu·∫•t metadata t·ª´ c√¢u truy v·∫•n kh√¥ng
            problem_only: Ch·ªâ l·∫•y ƒë·ªÅ b√†i kh√¥ng l·∫•y l·ªùi gi·∫£i
            
        Returns:
            Tuple[List[Document], bool]: (documents, success_flag)
            - documents: danh s√°ch documents t√¨m ƒë∆∞·ª£c ho·∫∑c r·ªóng n·∫øu l·ªói
            - success_flag: True n·∫øu retrieval th√†nh c√¥ng, False n·∫øu fallback
        """
        # Ki·ªÉm tra n·∫øu RAG b·ªã t·∫Øt trong settings ho·∫∑c kh√¥ng c√≥ k·∫øt n·ªëi Qdrant
        if not self.settings.rag_enabled or self.qdrant is None:
            logger.info("RAG is disabled or Qdrant connection not available. Returning empty context.")
            return [], False
            
        try:
            import time
            start_time = time.time()
            logger.info(f"üîç RAG QUERY: '{query}' (k={k}, use_metadata={use_query_metadata})")
            
            # Tr√≠ch xu·∫•t v√† k·∫øt h·ª£p metadata t·ª´ c√¢u truy v·∫•n (n·∫øu ƒë∆∞·ª£c b·∫≠t)
            combined_filter = filter or {}

            # L·∫•y s·ªë l∆∞·ª£ng k·∫øt qu·∫£ c·∫ßn tr·∫£ v·ªÅ
            k = k or self.rag_settings.top_k

            # ∆Øu ti√™n parser VN theo schema hi·ªán t·∫°i (category/subcategory/metadata.year)
            vn = parse_query(query)
            vn_filter = {}
            if vn.category:
                vn_filter["category"] = vn.category
            if vn.subcategory:
                vn_filter["subcategory"] = vn.subcategory
            if vn.year is not None:
                vn_filter["year"] = vn.year

            # If exam board is specified explicitly in query (bangA/bangB), enforce it
            if vn.subcategory in ("bangA", "bangB"):
                vn_filter["category"] = "dethi"
                vn_filter["subcategory"] = vn.subcategory

            # Handle question filtering
            if vn.question_code:  # "1.2", "3.1" - exact match for both dethi and baitap
                vn_filter["question_number"] = vn.question_code
            elif vn.question_num:  # "1", "2" - depends on category
                if vn_filter.get("category") == "dethi":
                    # For dethi: exact match on question number
                    vn_filter["question_number"] = vn.question_num
                elif vn_filter.get("category") == "baitap":
                    # For baitap: section match using problem_section field
                    vn_filter["problem_section"] = vn.question_num
            
            logger.info(f"üîß VN FILTER: {vn_filter}")

            # G·ªôp filter VN v√†o combined_filter (∆∞u ti√™n filter ƒë√£ c√≥ n·∫øu tr√πng)
            for key, value in vn_filter.items():
                combined_filter.setdefault(key, value)

            logger.info(f"Filter for query_points: {combined_filter}")
            
            # T·ªëi ∆∞u k cho Olympic context
            if combined_filter.get("_search_priority") == "olympic":
                k = min(k * 2, 10)  # T·ªëi ƒëa 10 documents cho Olympic
                logger.info(f"Olympic context detected, increased top_k to {k}")
            else:
                logger.info(f"Using standard top_k = {k}")
            
            # Chi·∫øn l∆∞·ª£c t√¨m ki·∫øm theo th·ª© t·ª± ∆∞u ti√™n
            documents = []
            search_success = False
            
            # 1. T√¨m ki·∫øm ch√≠nh x√°c v·ªõi s·ªë b√†i
            if "question_number" in combined_filter or "problem_section" in combined_filter:
                # Determine filter type and value
                if "question_number" in combined_filter:
                    q_val = str(combined_filter["question_number"]).strip()
                    logger.info(f"STRATEGY 1: Exact search with question_number: {q_val}")
                    exact_search_filter = {"question_number": q_val}
                elif "problem_section" in combined_filter:
                    section_val = str(combined_filter["problem_section"]).strip()
                    logger.info(f"STRATEGY 1: Section search with problem_section: {section_val}")
                    exact_search_filter = {"problem_section": section_val}
                else:
                    logger.warning("STRATEGY 1: No valid question filter found")
                    exact_search_filter = None
                
                # Th√™m nƒÉm n·∫øu c√≥ v√† filter h·ª£p l·ªá
                if exact_search_filter and "year" in combined_filter:
                    exact_search_filter["year"] = combined_filter["year"]
                    logger.info(f"Adding year {combined_filter['year']} to exact search filter")
                
                # B·∫£ng n·∫øu c√≥ v√† filter h·ª£p l·ªá
                if exact_search_filter and "subcategory" in combined_filter and combined_filter["subcategory"] in ("bangA", "bangB"):
                    exact_search_filter["subcategory"] = combined_filter["subcategory"]
                    exact_search_filter["category"] = "dethi"
                
                if exact_search_filter:
                    try:
                        # T√¨m ki·∫øm ch√≠nh x√°c theo s·ªë b√†i (v√† nƒÉm/board n·∫øu c√≥)
                        logger.info(f"Executing exact search with filter: {exact_search_filter}")
                        exact_docs = await self.qdrant.similarity_search(
                            query=query, 
                            k=k,
                            filter=exact_search_filter
                        )
                    
                        if exact_docs:
                            self._log_document_details(exact_docs, "STRATEGY 1:")
                            documents = exact_docs
                            search_success = True
                            logger.info("STRATEGY 1 successful - using these results")
                        else:
                            logger.info("STRATEGY 1: No documents found with exact question match")
                    except Exception as e:
                        logger.warning(f"STRATEGY 1: Error during exact search: {e}")
            
            # 2. N·∫øu kh√¥ng t√¨m th·∫•y theo s·ªë b√†i, t√¨m theo ch·ªß ƒë·ªÅ (tags) v√† s·ªë b√†i k·∫øt h·ª£p
            if not documents and "tags" in combined_filter and "question" in combined_filter:
                logger.info(f"STRATEGY 2: Topic + Question search with tags: {combined_filter['tags']} and question: {combined_filter['question']}")
                topic_question_filter = {
                    "tags": combined_filter["tags"],
                    "question": combined_filter["question"]
                }
                
                try:
                    logger.info(f"Executing topic+question search with filter: {topic_question_filter}")
                    topic_question_docs = await self.qdrant.similarity_search(
                        query=query, 
                        k=k,
                        filter=topic_question_filter
                    )
                    
                    if topic_question_docs:
                        self._log_document_details(topic_question_docs, "STRATEGY 2:")
                        documents = topic_question_docs
                        search_success = True
                        logger.info("STRATEGY 2 successful - using these results")
                    else:
                        logger.info("STRATEGY 2: No documents found with topic + question match")
                except Exception as e:
                    logger.warning(f"STRATEGY 2: Error during topic + question search: {e}")
            
            # 3. N·∫øu kh√¥ng t√¨m th·∫•y theo s·ªë b√†i k·∫øt h·ª£p tags, t√¨m theo ch·ªâ ri√™ng tags
            if not documents and "tags" in combined_filter:
                logger.info(f"STRATEGY 3: Topic search with tags: {combined_filter['tags']}")
                topic_search_filter = {"tags": combined_filter["tags"]}
                
                # Th√™m nƒÉm n·∫øu c√≥
                if "year" in combined_filter:
                    topic_search_filter["year"] = combined_filter["year"]
                    logger.info(f"Adding year {combined_filter['year']} to topic search filter")
                
                try:
                    logger.info(f"Executing topic search with filter: {topic_search_filter}")
                    topic_docs = await self.qdrant.similarity_search(
                        query=query, 
                        k=k,
                        filter=topic_search_filter
                    )
                    
                    if topic_docs:
                        self._log_document_details(topic_docs, "STRATEGY 3:")
                        documents = topic_docs
                        search_success = True
                        logger.info("STRATEGY 3 successful - using these results")
                    else:
                        logger.info("STRATEGY 3: No documents found with topic match")
                except Exception as e:
                    logger.warning(f"STRATEGY 3: Error during topic search: {e}")
            
            # 4. Cu·ªëi c√πng, t√¨m ki·∫øm v·ªõi filter ƒë·∫ßy ƒë·ªß, ho·∫∑c kh√¥ng c√≥ filter n·∫øu c√°c c√°ch tr√™n th·∫•t b·∫°i
            if not documents:
                search_filter = combined_filter if combined_filter else None
                logger.info(f"STRATEGY 4: Full semantic search with filter: {search_filter}")
                
                try:
                    logger.info(f"Executing semantic search with filter: {search_filter}")
                    semantic_docs = await self.qdrant.similarity_search(
                        query=query, 
                        k=k, 
                        filter=search_filter
                    )
                    
                    if semantic_docs:
                        self._log_document_details(semantic_docs, "STRATEGY 4:")
                        documents = semantic_docs
                        search_success = True
                        logger.info("STRATEGY 4 successful - using these results")
                    else:
                        logger.warning(f"STRATEGY 4: No documents found for query with filter: {query}")
                except Exception as e:
                    logger.error(f"STRATEGY 4: Error in semantic search: {e}")
                    
                    # Th·ª≠ l·∫°i l·∫ßn cu·ªëi kh√¥ng c√≥ filter n·∫øu tr∆∞·ªõc ƒë√≥ c√≥ d√πng filter
                    if search_filter:
                        try:
                            logger.info("STRATEGY 5: Final attempt - semantic search without filter")
                            final_docs = await self.qdrant.similarity_search(
                                query=query, 
                                k=k
                            )
                            
                            if final_docs:
                                self._log_document_details(final_docs, "STRATEGY 5:")
                                documents = final_docs
                                search_success = True
                                logger.info("STRATEGY 5 successful - using these results")
                            else:
                                logger.warning("STRATEGY 5: No documents found even without filter")
                        except Exception as retry_e:
                            logger.error(f"STRATEGY 5: Final attempt failed: {retry_e}")
            
            # ƒê√°nh d·∫•u documents n·∫øu ng∆∞·ªùi d√πng ch·ªâ mu·ªën xem ƒë·ªÅ b√†i
            if documents and problem_only:
                logger.info(f"Marking documents as problem_only = {problem_only}")
                for doc in documents:
                    # Th√™m flag v√†o metadata ƒë·ªÉ format_document bi·∫øt ch·ªâ l·∫•y ƒë·ªÅ b√†i
                    if not hasattr(doc, "metadata"):
                        doc.metadata = {}
                    doc.metadata["_looking_for_problem_only"] = True
            
            # No post-filtering needed - problem_section field handles baitap section queries directly
            
            # N·∫øu t√¨m th·∫•y b·∫•t k·ª≥ k·∫øt qu·∫£ n√†o
            if documents:
                elapsed = time.time() - start_time
                top_titles = [doc.metadata.get("title", "No title")[:50] for doc in documents[:3]]
                logger.info(f"‚úÖ RAG SUCCESS: {len(documents)} docs in {elapsed:.2f}s")
                logger.info(f"üìã Top results: {top_titles}")
                return documents, True
            
            # Kh√¥ng t√¨m th·∫•y g√¨ c·∫£
            elapsed = time.time() - start_time
            logger.warning(f"‚ùå RAG FAILED: No documents found in {elapsed:.2f}s")
            return [], False
            
        except Exception as e:
            # C∆° ch·∫ø fallback - ghi log l·ªói nh∆∞ng kh√¥ng l√†m h·ªèng tr·∫£i nghi·ªám ng∆∞·ªùi d√πng
            error_type = type(e).__name__
            logger.error(f"Error retrieving context: {error_type} - {e}")
            return [], False
    
    def format_context_for_prompt(self, documents: List[Document]) -> str:
        """
        ƒê·ªãnh d·∫°ng documents th√†nh context cho prompt (∆∞u ti√™n natural_*)
        S·ª≠ d·ª•ng context_builder ƒë·ªÉ gh√©p v√† th√™m citation title/source_file/year.
        """
        if not documents:
            return ""
        budget = getattr(self.rag_settings, 'context_token_budget', 1200)
        context, _ = assemble_context(documents, budget_tokens=budget)
        return context
    
    def format_context_for_display(self, documents: List[Document], query: str) -> str:
        """
        Format context ƒë·∫∑c bi·ªát cho vi·ªác hi·ªÉn th·ªã ƒë·ªÅ b√†i nguy√™n vƒÉn
        """
        from .prompts.templates import LinearAlgebraTemplates
        return LinearAlgebraTemplates.get_problem_display_prompt(query, documents)
    
    async def get_formatted_context(
        self, query: str, filter: Optional[Dict] = None, k: Optional[int] = None,
        use_query_metadata: bool = True
    ) -> Tuple[str, bool]:
        """
        L·∫•y v√† ƒë·ªãnh d·∫°ng context cho query v·ªõi h·ªó tr·ª£ display_mode
        
        Args:
            query: Truy v·∫•n ng∆∞·ªùi d√πng
            filter: B·ªô l·ªçc metadata
            k: S·ªë l∆∞·ª£ng documents l·∫•y v·ªÅ
            use_query_metadata: C√≥ tr√≠ch xu·∫•t metadata t·ª´ c√¢u truy v·∫•n kh√¥ng
            
        Returns:
            Tuple[str, bool]: (formatted_context, success_flag)
            - formatted_context: Context ƒë√£ ƒë·ªãnh d·∫°ng ho·∫∑c r·ªóng n·∫øu l·ªói
            - success_flag: True n·∫øu retrieval th√†nh c√¥ng, False n·∫øu fallback
        """
        # Tr√≠ch xu·∫•t metadata ƒë·ªÉ x√°c ƒë·ªãnh display_mode
        metadata = None
        if self.metadata_extractor and use_query_metadata:
            try:
                metadata = await self.metadata_extractor.extract_metadata(query)
                logger.info(f"Extracted metadata for formatting: {metadata}")
            except Exception as e:
                logger.warning(f"Error extracting metadata for formatting: {str(e)}")
        
        documents, success = await self.get_context(query, filter, k, use_query_metadata)
        if not success:
            return "", False
        
        # S·ª≠ d·ª•ng display_mode n·∫øu c√≥
        if metadata and hasattr(metadata, 'display_mode') and metadata.display_mode:
            logger.info("Using display mode for problem presentation")
            return self.format_context_for_display(documents, query), True
        else:
            return self.format_context_for_prompt(documents), True
    
    async def get_context_with_tiered_search(self, query: str, top_k: int = 5) -> List[Document]:
        """
        Truy xu·∫•t context s·ª≠ d·ª•ng tiered search strategy
        """
        try:
            # B∆∞·ªõc 1: Tr√≠ch xu·∫•t metadata
            if self.metadata_extractor:
                metadata = await self.metadata_extractor.extract_metadata(query)
                logger.info(f"Extracted metadata: {metadata}")
            else:
                # Fallback to old method
                metadata_dict = self._extract_metadata_from_query(query)
                metadata = MathQueryMetadata(
                    year=metadata_dict.get('year'),
                    exam=metadata_dict.get('exam'),
                    question=metadata_dict.get('question'),
                    level=metadata_dict.get('level'),
                    tags=metadata_dict.get('tags'),
                    requesting_solution=metadata_dict.get('requesting_solution', False)
                )
            
            # B∆∞·ªõc 2: Tiered search
            documents = await self._tiered_search(metadata, query, top_k)
            
            # B∆∞·ªõc 3: Tag context
            tagged_documents = self._tag_retrieved_context(documents, metadata.requesting_solution)
            
            return tagged_documents
            
        except Exception as e:
            logger.error(f"Error in get_context_with_tiered_search: {str(e)}")
            # Fallback: semantic search
            return await self._semantic_search_fallback(query, top_k)
    
    async def _tiered_search(self, metadata: MathQueryMetadata, query: str, top_k: int) -> List[Document]:
        """
        Th·ª±c hi·ªán t√¨m ki·∫øm 3 t·∫ßng
        """
        
        # T·∫ßng 1: Exact metadata matching
        if self._has_sufficient_metadata(metadata):
            logger.info("Trying Tier 1: Exact metadata matching")
            documents = await self._exact_metadata_search(metadata, top_k)
            if documents:
                logger.info(f"Tier 1 successful: found {len(documents)} documents")
                return documents
        
        # T·∫ßng 2: Hybrid search (metadata + semantic)
        logger.info("Trying Tier 2: Hybrid search")
        documents = await self._hybrid_search(metadata, query, top_k)
        if documents:
            logger.info(f"Tier 2 successful: found {len(documents)} documents")
            return documents
        
        # T·∫ßng 3: Pure semantic search
        logger.info("Trying Tier 3: Pure semantic search")
        documents = await self._semantic_search_fallback(query, top_k)
        logger.info(f"Tier 3 successful: found {len(documents)} documents")
        return documents

    def _has_sufficient_metadata(self, metadata: MathQueryMetadata) -> bool:
        """Ki·ªÉm tra xem c√≥ ƒë·ªß metadata ƒë·ªÉ th·ª±c hi·ªán exact search kh√¥ng - DEPRECATED"""
        # DEPRECATED: Using VN parser instead
        return False

    async def _exact_metadata_search(self, metadata: MathQueryMetadata, top_k: int) -> List[Document]:
        """T·∫ßng 1: T√¨m ki·∫øm ch√≠nh x√°c theo metadata"""
        try:
            if not self.qdrant:
                return []
                
            # T·∫°o filter cho Qdrant
            query_filter = {
                "year": metadata.year,
                "question": metadata.question,
                "level": metadata.level
            }
            if getattr(metadata, "exam", None):
                query_filter["exam"] = metadata.exam
            if getattr(metadata, "source", None):
                query_filter["source"] = metadata.source
            # N·∫øu ch·ªâ filter, d√πng HTTP API
            results = self.qdrant.search_with_filter_http(query_filter, limit=top_k)
            # Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ HTTP th√†nh Document n·∫øu c·∫ßn
            # ... gi·ªØ nguy√™n logic chuy·ªÉn ƒë·ªïi ...
            return results
        except Exception as e:
            logger.error(f"Error in exact metadata search: {str(e)}")
            return []

    async def _hybrid_search(self, metadata: MathQueryMetadata, query: str, top_k: int) -> List[Document]:
        """T·∫ßng 2: T√¨m ki·∫øm lai (metadata + semantic)"""
        try:
            if not self.qdrant:
                return await self._semantic_search_fallback(query, top_k)
                
            # T·∫°o filter n·ªõi l·ªèng
            query_filter = {}
            if metadata.year:
                query_filter["year"] = metadata.year
            if metadata.level:
                query_filter["level"] = metadata.level
            if metadata.tags:
                query_filter["tags"] = metadata.tags
            if getattr(metadata, "exam", None):
                query_filter["exam"] = metadata.exam
            if getattr(metadata, "source", None):
                query_filter["source"] = metadata.source
            # N·∫øu kh√¥ng c√≥ filter n√†o, chuy·ªÉn sang semantic
            if not query_filter:
                return await self._semantic_search_fallback(query, top_k)
            # N·∫øu ch·ªâ filter, d√πng HTTP API
            if not query:
                results = self.qdrant.search_with_filter_http(query_filter, limit=top_k)
                # Chuy·ªÉn ƒë·ªïi k·∫øt qu·∫£ HTTP th√†nh Document n·∫øu c·∫ßn
                # ... gi·ªØ nguy√™n logic chuy·ªÉn ƒë·ªïi ...
                return results
            # N·∫øu c√≥ vector, d√πng similarity_search nh∆∞ c≈©
            results = await self.qdrant.similarity_search(
                query=query,
                k=top_k,
                filter=query_filter
            )
            return results
        except Exception as e:
            logger.error(f"Error in hybrid search: {str(e)}")
            return await self._semantic_search_fallback(query, top_k)

    async def _semantic_search_fallback(self, query: str, top_k: int) -> List[Document]:
        """T·∫ßng 3: T√¨m ki·∫øm ng·ªØ nghƒ©a thu·∫ßn t√∫y"""
        try:
            if not self.qdrant:
                return []
            results = await self.qdrant.similarity_search(
                query=query,
                k=top_k,
                filter=None
            )
            return results
        except Exception as e:
            logger.error(f"Error in semantic search: {str(e)}")
            return []
    
    def _tag_retrieved_context(self, documents: List[Document], requesting_solution: bool) -> List[Document]:
        """
        G·∫Øn th·∫ª context v·ªõi <problem> v√† <solution> tags
        H·ªó tr·ª£ c·∫•u tr√∫c m·ªõi v·ªõi problem_statement v√† problem_parts
        """
        tagged_documents = []
        
        for doc in documents:
            try:
                # L·∫•y content t·ª´ c·∫•u tr√∫c m·ªõi ho·∫∑c c≈©
                problem_statement = doc.metadata.get('problem_statement', '')
                problem_parts = doc.metadata.get('problem_parts', {})
                
                # Fallback cho c·∫•u tr√∫c c≈©
                if not problem_statement:
                    problem_statement = doc.metadata.get('content', '')
                
                # T·∫°o n·ªôi dung ƒë·ªÅ b√†i ƒë·∫ßy ƒë·ªß
                full_problem_content = problem_statement
                
                # Th√™m problem_parts n·∫øu c√≥
                if problem_parts and isinstance(problem_parts, dict):
                    full_problem_content += "\n\n"
                    for part_key, part_content in problem_parts.items():
                        full_problem_content += f"\n**({part_key})** {part_content}\n"
                
                # T·∫°o tagged content
                tagged_content = f"<problem>{full_problem_content}</problem>"
                
                # Th√™m solution n·∫øu ƒë∆∞·ª£c y√™u c·∫ßu
                if requesting_solution:
                    # ∆Øu ti√™n c·∫•u tr√∫c m·ªõi
                    solution_data = doc.metadata.get('solution', {})
                    if solution_data and isinstance(solution_data, dict):
                        full_solution = solution_data.get('full_solution', '')
                        solution_parts = solution_data.get('solution_parts', {})
                        
                        if full_solution or solution_parts:
                            solution_content = full_solution
                            if solution_parts and isinstance(solution_parts, dict):
                                solution_content += "\n\n"
                                for part_key, part_solution in solution_parts.items():
                                    solution_content += f"**{part_key})** {part_solution}\n"
                            tagged_content += f"\n<solution_hints>{solution_content}</solution_hints>"
                    else:
                        # Fallback cho c·∫•u tr√∫c c≈©
                        suggested_solution = doc.metadata.get('suggested_solution', '')
                        if suggested_solution:
                            tagged_content += f"\n<solution>{suggested_solution}</solution>"
                
                # T·∫°o document m·ªõi v·ªõi content ƒë√£ tag
                tagged_doc = Document(
                    page_content=tagged_content,
                    metadata=doc.metadata
                )
                
                tagged_documents.append(tagged_doc)
                
            except Exception as e:
                logger.error(f"Error tagging document: {str(e)}")
                # Fallback: gi·ªØ nguy√™n document
                tagged_documents.append(doc)
        
        return tagged_documents

    async def get_context_with_history(
        self, 
        query: str, 
        chat_history: List = None,
        filter: Optional[Dict] = None,
        k: Optional[int] = None,
        use_query_metadata: bool = True,
        problem_only: bool = False
    ) -> Tuple[List[Document], bool]:
        """
        L·∫•y ng·ªØ c·∫£nh v·ªõi xem x√©t chat history ƒë·ªÉ x·ª≠ l√Ω follow-up questions
        
        Args:
            query: Truy v·∫•n ng∆∞·ªùi d√πng
            chat_history: L·ªãch s·ª≠ chat ƒë·ªÉ x·ª≠ l√Ω follow-up
            filter: B·ªô l·ªçc metadata
            k: S·ªë l∆∞·ª£ng documents l·∫•y v·ªÅ
            use_query_metadata: C√≥ tr√≠ch xu·∫•t metadata t·ª´ c√¢u truy v·∫•n kh√¥ng
            problem_only: Ch·ªâ l·∫•y ƒë·ªÅ b√†i kh√¥ng l·∫•y l·ªùi gi·∫£i
            
        Returns:
            Tuple[List[Document], bool]: (documents, success_flag)
        """
        try:
            # Tr√≠ch xu·∫•t metadata t·ª´ query
            extracted_filter = {}
            if use_query_metadata:
                extracted_filter = self._extract_metadata_from_query(query)
            
            # X·ª≠ l√Ω follow-up questions
            if extracted_filter.get("is_follow_up", False) and chat_history:
                logger.info("Processing follow-up question with chat history")
                return await self._handle_follow_up_with_history(query, chat_history)
            
            # N·∫øu kh√¥ng ph·∫£i follow-up, d√πng method th√¥ng th∆∞·ªùng
            return await self.get_context(
                query=query,
                filter=filter,
                k=k,
                use_query_metadata=use_query_metadata,
                problem_only=problem_only
            )
            
        except Exception as e:
            logger.error(f"Error in get_context_with_history: {str(e)}", exc_info=True)
            return [], False

    async def _handle_follow_up_with_history(self, query: str, chat_history: List) -> Tuple[List[Document], bool]:
        """
        X·ª≠ l√Ω follow-up questions b·∫±ng c√°ch t√¨m context t·ª´ chat history
        """
        try:
            logger.info("Handling follow-up question with chat history")
            
            # T√¨m response g·∫ßn nh·∫•t c·ªßa AI trong chat history
            last_ai_response = None
            for message in reversed(chat_history):
                if hasattr(message, 'role') and message.role == 'model':
                    last_ai_response = message.content
                    break
            
            if not last_ai_response:
                logger.info("No previous AI response found, using regular search")
                return await self.get_context(query, use_query_metadata=False)
            
            # Tr√≠ch xu·∫•t th√¥ng tin b√†i to√°n t·ª´ response tr∆∞·ªõc
            problem_info = self._extract_problem_info_from_response(last_ai_response)
            
            if problem_info:
                logger.info(f"Found problem info from previous response: {problem_info}")
                # T√¨m ki·∫øm v·ªõi th√¥ng tin b√†i to√°n c·ª• th·ªÉ
                return await self.get_context(
                    query=f"b√†i {problem_info.get('question', '')} {problem_info.get('category', '')}",
                    filter=problem_info,
                    use_query_metadata=False
                )
            else:
                # Fallback: t√¨m ki·∫øm r·ªông v·ªõi intent solution
                return await self.get_context(
                    query=query,
                    filter={"intent": "solution"},
                    use_query_metadata=False
                )
                
        except Exception as e:
            logger.error(f"Error handling follow-up: {str(e)}")
            return await self.get_context(query, use_query_metadata=False)

    def _extract_problem_info_from_response(self, response: str) -> Dict:
        """
        Tr√≠ch xu·∫•t th√¥ng tin b√†i to√°n t·ª´ response tr∆∞·ªõc ƒë√≥ - T·ªëi ∆∞u cho d·ªØ li·ªáu Olympic
        """
        import re
        problem_info = {}
        
        try:
            # T√¨m "B√†i X" trong response v·ªõi nhi·ªÅu pattern
            patterns = [
                r'B√†i\s+(\d+)',  # B√†i 1
                r'b√†i\s+(\d+)',  # b√†i 1
                r'ƒê·ªÅ\s+b√†i:\s*B√†i\s+(\d+)',  # ƒê·ªÅ b√†i: B√†i 1
            ]
            
            for pattern in patterns:
                bai_match = re.search(pattern, response)
                if bai_match:
                    problem_info["question"] = bai_match.group(1)
                    break
            
            # T√¨m lo·∫°i ƒë·ªÅ thi v·ªõi ƒë·ªô ∆∞u ti√™n cao
            if any(keyword in response for keyword in ["ƒê·ªÄ THI B·∫¢NG A", "ƒê·ªÅ thi B·∫£ng A", "B·∫¢NG A", "B·∫£ng A"]):
                problem_info["subcategory"] = "bangA"
                problem_info["category"] = "dethi"
                problem_info["exam_board"] = "BANGA"
            elif any(keyword in response for keyword in ["ƒê·ªÄ THI B·∫¢NG B", "ƒê·ªÅ thi B·∫£ng B", "B·∫¢NG B", "B·∫£ng B"]):
                problem_info["subcategory"] = "bangB"
                problem_info["category"] = "dethi"
                problem_info["exam_board"] = "BANGB"
            
            # T√¨m d·∫°ng b√†i t·∫≠p
            elif any(keyword in response for keyword in ["B√ÄI T·∫¨P", "B√†i t·∫≠p"]):
                problem_info["category"] = "baitap"
                # X√°c ƒë·ªãnh subcategory d·ª±a tr√™n n·ªôi dung
                if any(keyword in response for keyword in ["ma tr·∫≠n", "Ma tr·∫≠n"]):
                    problem_info["subcategory"] = "mt"
                elif any(keyword in response for keyword in ["ƒë·ªãnh th·ª©c", "ƒê·ªãnh th·ª©c"]):
                    problem_info["subcategory"] = "dt"
                elif any(keyword in response for keyword in ["h·ªá ph∆∞∆°ng tr√¨nh", "H·ªá ph∆∞∆°ng tr√¨nh"]):
                    problem_info["subcategory"] = "hpt"
                elif any(keyword in response for keyword in ["gi√° tr·ªã ri√™ng", "Gi√° tr·ªã ri√™ng"]):
                    problem_info["subcategory"] = "gtr"
            
            # T√¨m nƒÉm v·ªõi pattern c·∫£i thi·ªán
            year_patterns = [
                r'nƒÉm\s+(\d{4})',  # nƒÉm 2024
                r'(\d{4})',        # 2024
                r'NƒÉm:\s*(\d{4})', # NƒÉm: 2024
            ]
            
            for pattern in year_patterns:
                year_match = re.search(pattern, response)
                if year_match:
                    year = int(year_match.group(1))
                    if 2020 <= year <= 2030:  # Validate year range
                        problem_info["year"] = year
                        break
            
            # Th√™m metadata Olympic
            if problem_info.get("category") == "dethi":
                problem_info["difficulty_level"] = "quoc_gia"
                problem_info["subject_area"] = "dai_so_tuyen_tinh"
            
            logger.info(f"Extracted problem info: {problem_info}")
            return problem_info
            
        except Exception as e:
            logger.error(f"Error extracting problem info: {e}")
            return {} 